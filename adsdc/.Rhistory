summary(melt_mcor)
nrow(subset(melt_mcor, value>=0.9 & Var1!=Var2))
normaliy<-sapply(x, function(x) shapiro.test(x)$p.value)
var_norm_df<-data.frame(pvalue=normaliy,dist=ifelse(normaliy>=0.05,"non-normal p>0.05","normal"))
head(var_norm_df)
summary(var_norm_df)
p_variable_normality<-ggplot(var_norm_df,aes(x=factor(dist))) + geom_bar() +
labs(x = "Distribution")+
ggtitle("Count of non-nommal distributed variable")
p_variable_normality
names(normaliy[normaliy>=0.05])
summary(var_norm_df)
mean(rf_model_test == y.test) # RF test error
rf_model
str(rf_model)
summary(rf_model)
rf_model$err.rate
head(rf_model$err.rate)
plot(rf_model)
head(rf_model$err.rate)
summary(rf_model)
rf_model
rf_model$confusion
mean(svm_tuned_test == y.test)
mean(rf_model_test == y.test) # RF test error
print(svm_tune)
summary(rf_model)
print(rf_model)
table(rf_model_test, y.test) # test type I & II
table(svm_pred_tuned,y) # traning error
table(svm_tuned_test, y.test)
summary(svm_model_tuned)
table(svm_test, y.test)
summary(svm_model)
summary(svm_model_tuned)
summary(svm_model_tuned)
print(svm_tune)
svm_tune$best.parameters$cost
svm_model_tuned<-svm(class ~., data=train, type="C-classification", kernel="radial", cost=svm_tune$best.parameters$cost,gamma=svm_tune$best.parameters$gamma, cross=10)
summary(svm_model_tuned)
print(svm_tune)
table(svm_test, y.test)
mean(svm_test == y.test)
mean(svm_tuned_test == y.test)
table(svm_tuned_test, y.test)
summary(svm_model)
summary(svm_model_tuned)
((306-27)/306)^85
((306-27)/306)^85/100
((306-27)/306)^85*100
summary(svm_model)
1-svm_model_tuned$tot.accuracy/100
print(svm_tune)
1-svm_model$tot.accuracy/100
1-svm_model_tuned$tot.accuracy/100
print(svm_tune)
1-svm_model$tot.accuracy/100
1-svm_model_tuned$tot.accuracy/100
fit.training <- prcomp(train[,var_col], cor=TRUE)
fit.training <- prcomp(train[,var_col])
PCA.training <- prcomp(train[,var_col])
PCA.trainSet<-as.data.frame(fit$x[,1:10], class=train[,class_col])
View(PCA.trainSet)
PCA.trainSet<-as.data.frame(fit$x[,1:10], class=train[,class_col])
train[,class_col]
PCA.trainSet<-as.data.frame(fit$x[,1:10], class=train[,class_col])
View(PCA.trainSet)
PCA.trainSet<- data.frame(fit$x[,1:10], class=train[,class_col])
length(train[,class_col])
PCA.trainSet<- data.frame(PCA.training$x[,1:10], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:10], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svm_PCA_tune)
summary(svm_model_tuned)
svm_PCA_model <- svm(class ~., data=PCA.trainSet, type="C-classification", kernel="radial", cost=svm_PCA_tune$best.parameters$cost,gamma=svm_PCA_tune$best.parameters$gamma, cross=10)
1-svm_PCA_model$tot.accuracy/100
1-svm_model_tuned$tot.accuracy/100
PCA.trainSet<- data.frame(PCA.training$x[,1:2], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:2], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
svm_PCA_model <- svm(class ~., data=PCA.trainSet, type="C-classification", kernel="radial", cost=svm_PCA_tune$best.parameters$cost,gamma=svm_PCA_tune$best.parameters$gamma, cross=10)
1-svm_PCA_model$tot.accuracy/100
PCA.trainSet<- data.frame(PCA.training$x[,1:20], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:20], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
svm_PCA_model <- svm(class ~., data=PCA.trainSet, type="C-classification", kernel="radial", cost=svm_PCA_tune$best.parameters$cost,gamma=svm_PCA_tune$best.parameters$gamma, cross=10)
1-svm_PCA_model$tot.accuracy/100
nPC=9
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
svm_PCA_model <- svm(class ~., data=PCA.trainSet, type="C-classification", kernel="radial", cost=svm_PCA_tune$best.parameters$cost,gamma=svm_PCA_tune$best.parameters$gamma, cross=10)
1-svm_PCA_model$tot.accuracy/100
nPC=1
best.nPC = nPC
best.performance = 1
for (nPC in 1:20) {
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = 1-svm_PCA_model$tot.accuracy/100
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
}
}
best.nPC
best.performance
nPC=1
best.nPC = nPC
best.performance = 1
for (nPC in 1:20) {
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = 1-svm_PCA_model$tot.accuracy/100
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
}
nPC
new.performance
}
best.nPC
best.performance
print(nPC)
print(new.performance)
best.nPC = 1
best.performance = 1
for (nPC in 1:20) {
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = 1-svm_PCA_model$tot.accuracy/100
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
}
print(nPC)
print(new.performance)
}
best.nPC
best.performance
nPC=10
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = 1-svm_PCA_model$tot.accuracy/100
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
}
print(nPC)
print(new.performance)
nPC=10
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = svm_PCA_tune$best.performance
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
}
print(nPC)
print(new.performance)
best.nPC = 1
best.performance = 1
for (nPC in 1:20) {
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = svm_PCA_tune$best.performance
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
}
print(nPC)
print(new.performance)
}
best.nPC
best.performance
1:best.nPC
PCA.bestTrainSet<- data.frame(PCA.training$x[,1:best.nPC], class=train[,class_col])
svm_PCA_tune$best.parameters
PCA.training <- prcomp(train[,var_col])
best.nPC = 1
best.performance = 1
for (nPC in 1:20) {
PCA.trainSet<- data.frame(PCA.training$x[,1:nPC], class=train[,class_col])
svm_PCA_tune <- tune(svm, train.x=PCA.training$x[,1:nPC], train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
new.performance = svm_PCA_tune$best.performance
if(new.performance<best.performance){
best.performance = new.performance
best.nPC = nPC
best.parameter = svm_PCA_tune$best.parameters
}
}
best.nPC
best.performance
PCA.bestTrainSet<- data.frame(PCA.training$x[,1:best.nPC], class=train[,class_col])
svm_PCA_model <- svm(class ~., data=PCA.bestTrainSet, type="C-classification", kernel="radial", cost=best.parameters$cost,gamma=$best.parameters$gamma, cross=10)
PCA.bestTrainSet<- data.frame(PCA.training$x[,1:best.nPC], class=train[,class_col])
svm_PCA_model <- svm(class ~., data=PCA.bestTrainSet, type="C-classification", kernel="radial", cost=best.parameters$cost,gamma=$best.parameters$gamma, cross=10)
svm_PCA_model <- svm(class ~., data=PCA.bestTrainSet, type="C-classification", kernel="radial", cost=best.parameters$cost,gamma=best.parameters$gamma, cross=10)
best.parameter
svm_PCA_model <- svm(class ~., data=PCA.bestTrainSet, type="C-classification", kernel="radial", cost=best.parameter$cost,gamma=best.parameter$gamma, cross=10)
svm_PCA_model$tot.accuracy
1-svm_PCA_model$tot.accuracy/100
best.performance
1-svm_model_tuned$tot.accuracy/100
1-svm_PCA_model$tot.accuracy/100
install.packages("caret")
1-svm_PCA_model$tot.accuracy/100
svm_PCA_test<-predict(svm_PCA_model,x.test)
mcor[class]
mcor[,class]
str(mcor)
varClassCorr
head(varClassCorr)
varClassCorr[order(abs(varClassCorr), decreasing = T)[1:2]]
varClassCorr[order(abs(varClassCorr), decreasing = T)
varClassCorr[order(abs(varClassCorr), decreasing = T)}
varClassCorr[order(abs(varClassCorr), decreasing = T)]
order(abs(varClassCorr), decreasing = T)
varClassCorr[order(abs(varClassCorr), decreasing = T)]
1:ncol(train)
variable.seq<-order(abs(varClassCorr), decreasing = T)
var.sort[1:2]
var.sort<-order(abs(varClassCorr), decreasing = T)
var.sort[1:2]
train[,var.sort[1:2]]
svm_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
for (v in var_col){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
} else
break
}
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in var_col){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
} else
break
}
head(best.trainSet)
svm_best_tune$best.performance
svm_best_tune$best.performance
rbind(best.trainSet, y)
length(y)
length(best.trainSet)
cbind(best.trainSet, y)
head(cbind(best.trainSet, y))
cbind(best.trainSet, class=y)
svm_best_model<-svm(class ~., data=cbind(best.trainSet, class=y), type="C-classification", kernel="radial", cost=svm_tune$best.parameters$cost,gamma=svm_tune$best.parameters$gamma, cross=10)
svm_pred_tuned<-predict(svm_model_tuned,x.test)
svm_best_model_test<-predict(svm_best_model,x.test)
print(svm_tune)
table(svm_best_model_test, y.test)
mean(svm_best_model_test == y.test)
mean(rf_model_test == y.test) # RF test error
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 10){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 2){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 1:2){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 1:10){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 1:20){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 1:10){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 1:10){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
svm_best_tune$best.performance
svm_best_tune$best.parameters
svm_best_model<-svm(class ~., data=cbind(best.trainSet, class=y), type="C-classification", kernel="radial", cost=svm_best_tune$best.parameters$cost,gamma=svm_best_tune$best.parameters$gamma, cross=10)
svm_best_model_test<-predict(svm_best_model,x.test)
table(svm_best_model_test, y.test)
mean(svm_best_model_test == y.test)
summary(svm_model_tuned)
summary(svm_model_tuned)
summary(svm_best_model)
summary(svm_best_model)
summary(svm_model_tuned)
summary(svm_best_model)
summary(svm_model_tuned)
summary(svm_model)
summary(svm_best_model)
table(svm_tuned_test, y.test)
table(svm_best_model_test, y.test)
svm_best_tune$best.performance
summary(svm_model_tuned)
summary(svm_best_model)
summary(svm_model_tuned)
svm_model_tuned<-svm(class ~., data=train, type="C-classification", kernel="radial", cost=svm_tune$best.parameters$cost,gamma=svm_tune$best.parameters$gamma, cross=10)
svm_tune <- tune(svm, train.x=x, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
svm_model_tuned<-svm(class ~., data=train, type="C-classification", kernel="radial", cost=svm_tune$best.parameters$cost,gamma=svm_tune$best.parameters$gamma, cross=10)
summary(svm_model_tuned)
summary(svm_best_model)
summary(svm_model_tuned)
summary(svm_best_model)
var.sort<-order(abs(varClassCorr), decreasing = T)
best.performance=1
svm_best_tune = svm_tune
best.trainSet = train
for (v in 1:10){
trainSet<- train[,var.sort[1:v]]
svm_tune <- tune(svm, train.x=trainSet, train.y=y, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
if(svm_tune$best.performance < best.performance){
best.performance = svm_tune$best.performance
svm_best_tune = svm_tune
best.trainSet = trainSet
}
}
head(best.trainSet)
svm_best_tune$best.performance
table(svm_test, y.test)
1-svm_model$tot.accuracy/100
rf_model$confusion
rf_model
rf_model$oob.times
str(rf_model)
print(rf_model)
rf_model$err.rate
rf_model$err
rf_model$oob
rf_model$oob.err
rf_model
rf_model$proximity
rf_model$votes
rf_model$
rf_model$err.rate
rf_model$err.rate
head(rf_model$err.rate)
mean(rf_model$err.rate)$OOB
mean((rf_model$err.rate)$OOB)
(rf_model$err.rate)$OOB
str(rf_model$err.rate)
mean((rf_model$err.rate)[1])
mean((rf_model$err.rate)[[1]])
(rf_model$err.rate)[[1]]
(rf_model$err.rate)[1]
(rf_model$err.rate)[1,]
(rf_model$err.rate)[,1]
mean((rf_model$err.rate)[,1])
143/(143+59)
mean(rf_model_test == y.test) # RF test error
min((rf_model$err.rate)[,1])
min((rf_model$err.rate)[,1])
rf_model <- randomForest(as.factor(class) ~ ., data=train, importance=TRUE, ntree=200)
plot(rf_model)
print(rf_model)
pred_rf<-predict(rf_model,x)
table(pred_rf,y) # type I & II
mean(pred_rf == y) # RF training error
rf_model_test<-predict(rf_model,x.test)
table(rf_model_test, y.test) # test type I & II
mean(rf_model_test == y.test) # RF test error
min((rf_model$err.rate)[,1])
rf_model <- randomForest(as.factor(class) ~ ., data=train, importance=TRUE, ntree=2000)
plot(rf_model)
print(rf_model)
pred_rf<-predict(rf_model,x)
table(pred_rf,y) # type I & II
mean(pred_rf == y) # RF training error
rf_model_test<-predict(rf_model,x.test)
table(rf_model_test, y.test) # test type I & II
mean(rf_model_test == y.test) # RF test error
min((rf_model$err.rate)[,1])
mean((rf_model$err.rate)[,1])
rf_model
median((rf_model$err.rate)[,1])
rf_model <- randomForest(as.factor(class) ~ ., data=train, importance=TRUE, ntree=20)
plot(rf_model)
print(rf_model)
pred_rf<-predict(rf_model,x)
table(pred_rf,y) # type I & II
mean(pred_rf == y) # RF training error
rf_model_test<-predict(rf_model,x.test)
table(rf_model_test, y.test) # test type I & II
mean(rf_model_test == y.test) # RF test error
rf_model
median((rf_model$err.rate)[,1])
svm_best_model
svm_best_tune
mean(svm_best_model_test == y.test)
mean(svm_best_model_test == y.test)
svm_best_tune
svm_best_tune$best.performance
mean(svm_best_model_test == y.test)
1-mean(svm_best_model_test == y.test)
svm_best_tune$best.performance
median((rf_model$err.rate)[,1])
1-mean(rf_model_test == y.test)
rf_model <- randomForest(as.factor(class) ~ ., data=train, importance=TRUE, ntree=2000)
plot(rf_model)
print(rf_model)
pred_rf<-predict(rf_model,x)
table(pred_rf,y) # type I & II
mean(pred_rf == y) # RF training error
rf_model_test<-predict(rf_model,x.test)
table(rf_model_test, y.test) # test type I & II
mean(rf_model_test == y.test) # RF test error
rf_model
median((rf_model$err.rate)[,1])
median((rf_model$err.rate)[,1])
1-mean(rf_model_test == y.test)
rf_model
rf_model
median((rf_model$err.rate)[,1])
summary(svm_tune)
svm_tune
colnames(best.trainSet)
svm_best_model
1-mean(svm_best_model_test == y.test)
